<!--project: my Perceptron - Anya Chaliotis -->
<!--work for UW, iSchool, INFX598 Advanced Data Vis, taught by Jessica Hullman -->
<!--inspired by INFX574 DataSciII, taught by Joshua Blumenstock -->


<!DOCTYPE html>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<link rel="stylesheet" href="myPerceptron.css">
<title>My Perceptron Visualized</title>
<h1>Two Perceptrons is Better Than One</h1>
<h2>INFX574: DataSci meets INFX598: DataVis</h2>
<h3>Perceptron: what is it?</h3>
<a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Neuron/index.html" class="text_credits">Site credits: https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Neuron/index.html</a>
<p>The perceptron is a mathematical model of a biological neuron. While in actual neurons the dendrite receives electrical signals from the axons of other neurons, in the perceptron these electrical signals are represented as numerical values. At the synapses between the dendrite and axons, electrical signals are modulated in various amounts. This is also modeled in the perceptron by multiplying each input value by a value called the weight. An actual neuron fires an output signal only when the total strength of the input signals exceed a certain threshold. We model this phenomenon in a perceptron by calculating the weighted sum of the inputs to represent the total strength of the input signals, and applying a step function on the sum to determine its output. As in biological neural networks, this output is fed to other perceptrons.</p>
<table class="noBorder">
  <tr>
    <td>
      <img src="img/bioneuron.jpg" alt=" A biological neuron">
    </td>
    <td>
      <img src="img/artificial.jpg" alt="An artificial neuron (perceptron)">
    </td>
  </tr>
  <tr>
    <td>
      A biological neuron
    </td>
    <td>
      An artificial neuron (perceptron)
    </td>
  </tr>
</table>
<br><br>
<h3>What Can a perceptron do?</h3>
  A perceptron calculates the weighted sum of the input values.  Let's assume two input values, x1 and x2 for a certain perceptron. Let the weights for x1 and x2 be w1 and w2 respectively, the weighted sum could be represented as: w1 x1 + w2 x2.  Since the perceptron outputs an non-zero value only when the weighted sum exceeds a certain threshold, one can write down the output of this perceptron as follows:<p>

<table class="noBorder">
  <tr>
    <td>
      y =
    </td>
    <td>
      {1 &nbsp;&nbsp;if w1 x1 + w2 x2 > threshold
    </td>
  </tr>
  <tr>
    <td>
      &nbsp;
    </td>
    <td>
      &nbsp;&nbsp;&nbsp;{0 &nbsp;&nbsp;if w1 x1 + w2 x2 < = threshold
    </td>
  </tr>
</table>
<br><br>
<h3>Single Perceptron meets Truth table</h3>
This result is useful because it turns out that some logic functions such as the boolean AND, OR and other operators can be performed using a single perceprton.  For more theory, please refer to <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Neuron/index.html">Neural Network web site - the Artificial Neuron</a>
<br>This was a theoretical introduction, now let's play and visualize our protogonist Perceptron.<br><br><br>
    <br><br><br><br>
<div id='container'>
  <div id='sections'>
    <div><!--0-->
    The idea is that given the truth table for a logical function, Perceptron can accurately predict the outcome for each truth pair by applying weights and using a step function to determine the action potential.
    </div>

    <!--1-->
    <div>Let's start from pairs of x1 and x2. Our hero Perceptron will take all possible pairs of the truth table for AND function and predict their outcome.    We use <span style="color:red;">red</span> and <span style="color:blue;">blue</span> to represent boolean values of <span style="color:red;">1-True</span> and <span style="color:blue;">0-False</span> respectively.  
    </div>

    <!--2-->
    <div>
      <h3>Single Perceptron and AND</h3>
      <table width=80% align="center" border=1 >
      <tr bgcolor="orange">
        <td>
          x1
        </td>
        <td>
          x2
        </td>
        <td>
          y
        </td>
      </tr>
      <tr>
        <td>
          1
        </td>
        <td>
          1
        </td>
        <td>
          1
        </td>
      </tr>
      <tr>
        <td>
          1
        </td>
        <td>
          0
        </td>
        <td>
          0
        </td>
      </tr>
      <tr>
        <td>
          0
        </td>
        <td>
          1
        </td>
        <td>
          0
        </td>
      </tr>
      <tr>
        <td>
          0
        </td>
        <td>
          0
        </td>
        <td>
          0
        </td>
      </tr>
    </table>
    </div>

    <!--3-->
    <div>
    Well done!<br>  Now, back to pairs of x1 and x2 and predicting OR function.    
    </div>

    <!--4-->
    <div>
      <h3>Single Perceptron and OR</h3>
      <table width=80% align="center" border=1 >
      <tr bgcolor="orange">
        <td>
          x1
        </td>
        <td>
          x2
        </td>
        <td>
          y
        </td>
      </tr>
      <tr>
        <td>
          1
        </td>
        <td>
          1
        </td>
        <td>
          1
        </td>
      </tr>
      <tr>
        <td>
          1
        </td>
        <td>
          0
        </td>
        <td>
          1
        </td>
      </tr>
      <tr>
        <td>
          0
        </td>
        <td>
          1
        </td>
        <td>
          1
        </td>
      </tr>
      <tr>
        <td>
          0
        </td>
        <td>
          0
        </td>
        <td>
          0
        </td>
      </tr>
    </table>
    </div>

    <!--5-->
    <div>
    Well done again!<br>  Now, back to pairs of x1 and x2 and predicting XOR function.     
    </div>

    <!--6-->
    <div>
      <h3>Single Perceptron and XOR?</h3>

      <table width=80% align="center" border=1 >
      <tr bgcolor="orange">
        <td>
          x1
        </td>
        <td>
          x2
        </td>
        <td>
          y
        </td>
      </tr>
      <tr>
        <td>
          1
        </td>
        <td>
          1
        </td>
        <td>
          0
        </td>
      </tr>
      <tr>
        <td>
          1
        </td>
        <td>
          0
        </td>
        <td>
          1
        </td>
      </tr>
      <tr>
        <td>
          0
        </td>
        <td>
          1
        </td>
        <td>
          1
        </td>
      </tr>
      <tr>
        <td>
          0
        </td>
        <td>
          0
        </td>
        <td>
          0
        </td>
      </tr>
    </table>
    </div>

    <!--7--><div>
      <h3>Want to try on your own?</h3>
      So far the magic of a perceptron "firing" was hidden from you.  If you'd like to see how it works for each pair, check out<br> 
      <a href="myPerceptron1Layer.html" class="text_highlight">Single Perceptron in Action</a> <br><br><br>
      Still working on XOR?  You can keep trying or take our word for it: it's impossible.  And here's why...
    </div>

  </div>

  <div id='graph'></div>
</div>

<h3>Single Perceptron Geometrically</h3>

<div id='container2'>
XOR is not linearly separable, therefore it can't be solved by a single perceptron.<br>
<img src="img/3Amigos.png" style="width:100%;" ></img><br><br>
<span class="text_credits"> Image credits: University of Washington, INFX574 - Joshua Blumenstock - iSchool </span>
<h3>So Perceptron was abondoned...</h3>
<p>Time went by.  Machines grew stronger.  Truth hasn't aged at all.  And XOR still needed to be solved...  The question remained: how?</p>
<br>
<h3>A genious idea!</h3>If a single perceptron can't resolve the XOR problem, what about two perceptrons?<br>Give it another try with<br>
<a href="myPerceptron2Layers.html" class="text_highlight">More than One Perceptron</a> <br><br><br>
And that's why we titled this exploration as 'Two Perceptrons is Better Than One'!

And the story hasn't ended here.  Layering perceptrons gave rise to neural networks, advanced the field of computing, and became part of data science curriculum!  

</div>
<div>
  <h3>Citations</h3>
  <p>
    <a href='https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/index.html'>Neural Networks</a>
  </p>
  <p><a href='https://github.com/1wheel/graph-scroll'>Simple scrolling events for d3 graphs</a></p>
</div>

<!-- libraries -->
<script src="d3.v3.js"></script>
<script src="graph-scroll.js"></script>
<script type="text/javascript" src="myPerceptron.js"></script>
